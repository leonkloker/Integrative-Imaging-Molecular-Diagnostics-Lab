{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import PIL.ImageColor as ImageColor\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for clustering algorithm\n",
    "data_index = [\"H-15\", \"A-15\", \"B-11\", \"A-7\", \"F-9\", \"G-3\", \"G-11\", \"H-7\", \"I-13\"]\n",
    "path_cores = \"TMA_cores_M06_M07_panels/M06/Cores/\"\n",
    "path_mxIF = \"Texts_small_coregistered/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cores = [cv.imread(path_cores + index + \".png\") for index in data_index]\n",
    "data_mxIF = [pd.read_csv(path_mxIF + index + \".csv\") for index in data_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER = 50\n",
    "BATCH = 64\n",
    "CELL_SIZE = (32, 32)\n",
    "MXIF_FEATURES = [\"Nucleus PD1 (PPD520) Mean (Normalized Counts, Total Weighting)\",\n",
    "                 \"Nucleus PD1 (PPD520) Max (Normalized Counts, Total Weighting)\",\n",
    "                 \"Nucleus PD1 (PPD520) Std Dev (Normalized Counts, Total Weighting)\",\n",
    "                 \"Nucleus FOXP3 (PPD540) Mean (Normalized Counts, Total Weighting)\",\n",
    "                 \"Nucleus FOXP3 (PPD540) Max (Normalized Counts, Total Weighting)\",\n",
    "                 \"Nucleus FOXP3 (PPD540) Std Dev (Normalized Counts, Total Weighting)\",\n",
    "                 \"Nucleus CD20 (PPD620) Mean (Normalized Counts, Total Weighting)\",\n",
    "                 \"Nucleus CD20 (PPD620) Max (Normalized Counts, Total Weighting)\",\n",
    "                 \"Nucleus CD20 (PPD620) Std Dev (Normalized Counts, Total Weighting)\",\n",
    "                 \"Nucleus CD3 (PPD650) Mean (Normalized Counts, Total Weighting)\",\n",
    "                 \"Nucleus CD3 (PPD650) Max (Normalized Counts, Total Weighting)\",\n",
    "                 \"Nucleus CD3 (PPD650) Std Dev (Normalized Counts, Total Weighting)\",\n",
    "                 \"Nucleus PANCK (PPD690) Mean (Normalized Counts, Total Weighting)\",\n",
    "                 \"Nucleus PANCK (PPD690) Max (Normalized Counts, Total Weighting)\",\n",
    "                 \"Nucleus PANCK (PPD690) Std Dev (Normalized Counts, Total Weighting)\",\n",
    "                 \"Cytoplasm PD1 (PPD520) Mean (Normalized Counts, Total Weighting)\",\n",
    "                 \"Cytoplasm PD1 (PPD520) Max (Normalized Counts, Total Weighting)\",\n",
    "                 \"Cytoplasm PD1 (PPD520) Std Dev (Normalized Counts, Total Weighting)\",\n",
    "                 \"Cytoplasm FOXP3 (PPD540) Mean (Normalized Counts, Total Weighting)\",\n",
    "                 \"Cytoplasm FOXP3 (PPD540) Max (Normalized Counts, Total Weighting)\",\n",
    "                 \"Cytoplasm FOXP3 (PPD540) Std Dev (Normalized Counts, Total Weighting)\",\n",
    "                 \"Cytoplasm CD20 (PPD620) Mean (Normalized Counts, Total Weighting)\",\n",
    "                 \"Cytoplasm CD20 (PPD620) Max (Normalized Counts, Total Weighting)\",\n",
    "                 \"Cytoplasm CD20 (PPD620) Std Dev (Normalized Counts, Total Weighting)\",\n",
    "                 \"Cytoplasm CD3 (PPD650) Mean (Normalized Counts, Total Weighting)\",\n",
    "                 \"Cytoplasm CD3 (PPD650) Max (Normalized Counts, Total Weighting)\",\n",
    "                 \"Cytoplasm CD3 (PPD650) Std Dev (Normalized Counts, Total Weighting)\",\n",
    "                 \"Cytoplasm PANCK (PPD690) Mean (Normalized Counts, Total Weighting)\",\n",
    "                 \"Cytoplasm PANCK (PPD690) Max (Normalized Counts, Total Weighting)\",\n",
    "                 \"Cytoplasm PANCK (PPD690) Std Dev (Normalized Counts, Total Weighting)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_MAX = np.zeros(len(MXIF_FEATURES))\n",
    "TOTAL_MIN = np.zeros(len(MXIF_FEATURES))\n",
    "\n",
    "for i, feature in enumerate(MXIF_FEATURES):\n",
    "    for core in train_mxIF:\n",
    "        current_max = core.loc[:,feature].max()\n",
    "        current_min = core.loc[:,feature].min()\n",
    "        if current_max > TOTAL_MAX[i]:\n",
    "            TOTAL_MAX[i] = current_max\n",
    "        if current_min < TOTAL_MIN[i]:\n",
    "            TOTAL_MIN[i] = current_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(mxIF, cores):\n",
    "    def data_generator():\n",
    "        for i in range(len(mxIF)):\n",
    "            X = mxIF[i].loc[:,'Cell X Position']\n",
    "            Y = mxIF[i].loc[:,'Cell Y Position']\n",
    "\n",
    "            for j,(x,y) in enumerate(zip(X, Y)):\n",
    "                x = float(x)\n",
    "                y = float(y)\n",
    "                if np.isnan(x) or np.isnan(y):\n",
    "                    continue\n",
    "                if round(x - CELL_SIZE[0]) < 0 or round(x + CELL_SIZE[0]) >= cores[i].shape[1]:\n",
    "                    continue\n",
    "                if round(y - CELL_SIZE[1]) < 0 or round(y + CELL_SIZE[1]) >= cores[i].shape[0]:\n",
    "                    continue\n",
    "\n",
    "                cell_image = cores[i][round(y-CELL_SIZE[1]):round(y+CELL_SIZE[1]),\n",
    "                                            round(x-CELL_SIZE[0]):round(x+CELL_SIZE[0])] / 255\n",
    "                    \n",
    "                cell_features = np.array(mxIF[i].loc[j, MXIF_FEATURES], dtype=np.float32)\n",
    "                cell_features = (cell_features - TOTAL_MIN) / TOTAL_MAX\n",
    "                    \n",
    "                if np.sum(np.isnan(cell_features)) != 0:\n",
    "                    continue\n",
    "\n",
    "                yield (cell_image, cell_features)\n",
    "                \n",
    "    return data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_coordinate_generator():\n",
    "    for i in range(len(data_index)):\n",
    "        X = data_mxIF[i].loc[:,'Cell X Position']\n",
    "        Y = data_mxIF[i].loc[:,'Cell Y Position']\n",
    "\n",
    "        for j,(x,y) in enumerate(zip(X, Y)):\n",
    "            x = float(x)\n",
    "            y = float(y)\n",
    "            if np.isnan(x) or np.isnan(y):\n",
    "                continue\n",
    "            if round(x - CELL_SIZE[0]) < 0 or round(x + CELL_SIZE[0]) >= data_cores[i].shape[1]:\n",
    "                continue\n",
    "            if round(y - CELL_SIZE[1]) < 0 or round(y + CELL_SIZE[1]) >= data_cores[i].shape[0]:\n",
    "                continue\n",
    "\n",
    "            yield (x, y), i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 20:11:43.829805: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/leonkl/anaconda3/envs/LAB/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-03-15 20:11:43.829858: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-15 20:11:43.829884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (icme-gpu1): /proc/driver/nvidia/version does not exist\n",
      "2023-03-15 20:11:43.830312: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "data = tf.data.Dataset.from_generator(get_generator(data_mxIF, data_cores),\n",
    "                                       output_signature=(tf.TensorSpec(shape=(2*CELL_SIZE[1],2*CELL_SIZE[0],3), dtype=tf.float32),\n",
    "                                                          tf.TensorSpec(shape=(len(MXIF_FEATURES)), dtype=tf.float32)))\n",
    "data = data.batch(BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = \"logs/autoencoder/baseline_big/ffn_dropout/20230314-220323/\"\n",
    "loaded_model = tf.saved_model.load(load_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "# calculate the latent vectors of all the training data\n",
    "data_latent = []\n",
    "for i, elem in enumerate(data):\n",
    "    latent_he = loaded_model.encoder_conv(elem[0])\n",
    "    latent_mxIF = loaded_model.encoder_fnn(elem[1])\n",
    "    latent_he = latent_he.numpy()\n",
    "    latent_mxIF = latent_mxIF.numpy()\n",
    "    data_latent.append(np.concatenate([latent_he, latent_mxIF], axis=1))\n",
    "    if i % 500 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate K cluster centroids in the latent space\n",
    "K = 10\n",
    "vectors_latent = np.concatenate(data_latent, axis=0)\n",
    "vectors_latent_w = normalize(vectors_latent)\n",
    "\n",
    "clusterer = KMeans(n_clusters=K).fit(vectors_latent_w)\n",
    "labels = clusterer.predict(vectors_latent_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define colors for the K clusters\n",
    "colormap = ['#0000FF', '#8A2BE2', '#FF4040', '#8A360F', '#98F5FF', '#FF6103', '#7FFF00', '#EEE8CD', '#FFB90F', '#556B2F', '#EE1289']\n",
    "colormap = [ImageColor.getcolor(color, \"RGB\") for color in colormap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot the clustered cells in thre original H&E image for visualization\n",
    "core_inx = 3\n",
    "src = data_cores[core_inx]\n",
    "cells = cell_coordinate_generator()\n",
    "for i, ((x, y), j) in enumerate(cells):\n",
    "    if j == core_inx:\n",
    "        cv.circle(src, (int(x),int(y)), radius=4, color=colormap[int(labels[i])], thickness=-1)\n",
    "    if j > core_inx:\n",
    "        break\n",
    "\n",
    "\n",
    "cv.imwrite(\"cluster.png\", src)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LAB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
